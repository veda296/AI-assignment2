{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.optimizers import Adam\n",
    "import keras\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from keras.utils import to_categorical\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "import cv2\n",
    "import os\n",
    "import pickle\n",
    "if not os.path.exists('pickled_1'):\n",
    "    os.makedirs('pickled_1')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "\n",
    "data = []\n",
    "labels = []\n",
    "if not os.path.exists('pickled_1/melanoma_data.pkl'):\n",
    "    directory = os.fsencode(\"melanoma\")\n",
    "    for file in os.listdir(directory):\n",
    "        filename = os.fsdecode(file)\n",
    "        path = str('melanoma\\\\' + filename)\n",
    "        image = cv2.imread(path)\n",
    "        \n",
    "        #print(\"here\")\n",
    "        #cv2.imshow(image)\n",
    "        \n",
    "        image = cv2.resize(image, (64, 64))\n",
    "        image = img_to_array(image)\n",
    "        data.append(image)\n",
    "        labels.append(1)\n",
    "\n",
    "    directory = os.fsencode(\"others\")\n",
    "    for file in os.listdir(directory):\n",
    "        filename = os.fsdecode(file)\n",
    "        path = str('others\\\\' + filename)\n",
    "        image = cv2.imread(path)\n",
    "        image = cv2.resize(image, (64, 64))\n",
    "        image = img_to_array(image)\n",
    "        data.append(image)\n",
    "        labels.append(0)\n",
    "    d = {}\n",
    "    d['data'] = data\n",
    "    d['labels'] = labels\n",
    "    pickle.dump(d, open('pickled_1/melanoma_data.pkl', 'wb'))\n",
    "else:\n",
    "    d = pickle.load(open( 'pickled_1/melanoma_data.pkl', 'rb'))\n",
    "    data = d['data']\n",
    "    labels = d['labels']\n",
    "                \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.array(data, dtype=\"float\") / 255.0\n",
    "labels = np.array(labels)\n",
    "\n",
    "(x_train, x_test, y_train, y_test) = train_test_split(data,labels, test_size=0.20, random_state=42)\n",
    "y_train = to_categorical(y_train, num_classes=2)\n",
    "y_test = to_categorical(y_test, num_classes=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (1600, 64, 64, 3)\n",
      "1600 train samples\n",
      "400 test samples\n",
      "Train on 1600 samples, validate on 400 samples\n",
      "Epoch 1/10\n",
      "1600/1600 [==============================] - 19s 12ms/step - loss: 0.5849 - acc: 0.8025 - val_loss: 0.4957 - val_acc: 0.8050\n",
      "Epoch 2/10\n",
      "1600/1600 [==============================] - 19s 12ms/step - loss: 0.5012 - acc: 0.8150 - val_loss: 0.4920 - val_acc: 0.8050\n",
      "Epoch 3/10\n",
      "1600/1600 [==============================] - 19s 12ms/step - loss: 0.5141 - acc: 0.8150 - val_loss: 0.4908 - val_acc: 0.8050\n",
      "Epoch 4/10\n",
      "1600/1600 [==============================] - 18s 11ms/step - loss: 0.5134 - acc: 0.8150 - val_loss: 0.4844 - val_acc: 0.8050\n",
      "Epoch 5/10\n",
      "1600/1600 [==============================] - 18s 11ms/step - loss: 0.5093 - acc: 0.8150 - val_loss: 0.4678 - val_acc: 0.8050\n",
      "Epoch 6/10\n",
      "1600/1600 [==============================] - 18s 11ms/step - loss: 0.4921 - acc: 0.8150 - val_loss: 0.4715 - val_acc: 0.8050\n",
      "Epoch 7/10\n",
      "1600/1600 [==============================] - 18s 11ms/step - loss: 0.5056 - acc: 0.8150 - val_loss: 0.4742 - val_acc: 0.8050\n",
      "Epoch 8/10\n",
      "1600/1600 [==============================] - 18s 11ms/step - loss: 0.4845 - acc: 0.8150 - val_loss: 0.5110 - val_acc: 0.8050\n",
      "Epoch 9/10\n",
      "1600/1600 [==============================] - 18s 11ms/step - loss: 0.4847 - acc: 0.8150 - val_loss: 0.4693 - val_acc: 0.8050\n",
      "Epoch 10/10\n",
      "1600/1600 [==============================] - 18s 11ms/step - loss: 0.4882 - acc: 0.8150 - val_loss: 0.4920 - val_acc: 0.8050\n",
      "Test loss: 0.4919578075408936\n",
      "Test accuracy: 0.805\n"
     ]
    }
   ],
   "source": [
    "batch_size = 60\n",
    "num_classes = 2\n",
    "epochs = 10\n",
    "\n",
    "img_rows, img_cols = 64, 64\n",
    "\n",
    "input_shape = (img_rows, img_cols,3)\n",
    "\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(3, 3),activation='relu',input_shape=input_shape))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.75))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adadelta(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          validation_data=(x_test, y_test))\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
