{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.optimizers import Adam\n",
    "import keras\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from keras.utils import to_categorical\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "import numpy as np\n",
    "import random\n",
    "from keras import backend as K\n",
    "import cv2\n",
    "from collections import Counter\n",
    "from sklearn.utils import class_weight\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import classification_report\n",
    "import pickle\n",
    "import tensorflow as tf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def rotate_images(img):\n",
    "    X_rotate = []\n",
    "    tf.reset_default_graph()\n",
    "    X = tf.placeholder(tf.float32, shape = (128, 128, 3))\n",
    "    k = tf.placeholder(tf.int32)\n",
    "    tf_img = tf.image.rot90(X, k = k)\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        for i in range(3):\n",
    "            rotated_img = sess.run(tf_img, feed_dict = {X: img, k: i + 1})\n",
    "            X_rotate.append(rotated_img)\n",
    "            \n",
    "    #X_rotate = np.array(X_rotate, dtype = np.float32)\n",
    "    return X_rotate[0],X_rotate[1],X_rotate[2]\n",
    "\n",
    "\n",
    "data = []\n",
    "labels = []\n",
    "\n",
    "if not os.path.exists('data2.pkl'):\n",
    "        \n",
    "    directory = os.fsencode(\"melanoma\")\n",
    "    for file in os.listdir(directory):\n",
    "        filename = os.fsdecode(file)\n",
    "        path = str('melanoma\\\\' + filename)\n",
    "        image = cv2.imread(path)\n",
    "        \n",
    "        path = str('gt\\\\' + filename.split('.')[0] + '_segmentation.png')\n",
    "        image_mask = cv2.imread(path)\n",
    "        image = cv2.bitwise_and(image,image_mask)\n",
    "        image = cv2.resize(image, (128, 128))\n",
    "        image = img_to_array(image)\n",
    "        \n",
    "        r1,r2,r3 = rotate_images(image)\n",
    "        data.append(image)\n",
    "        labels.append(1)\n",
    "        data.append(r1)\n",
    "        data.append(r2)\n",
    "        data.append(r3)\n",
    "        \n",
    "        #imgplot = plt.imshow(image)\n",
    "        #plt.show()\n",
    "        \n",
    "        labels.append(1)    \n",
    "        labels.append(1)    \n",
    "        labels.append(1)        \n",
    "    \n",
    "    directory = os.fsencode(\"others\")\n",
    "    for file in os.listdir(directory):\n",
    "        filename = os.fsdecode(file)\n",
    "        path = str('others\\\\' + filename)\n",
    "        image = cv2.imread(path)\n",
    "        path = str('gt\\\\' + filename.split('.')[0] + '_segmentation.png')\n",
    "        image_mask = cv2.imread(path)\n",
    "        image = cv2.bitwise_and(image,image_mask)\n",
    "        \n",
    "        image = cv2.resize(image, (128, 128))\n",
    "        image = img_to_array(image)\n",
    "        \n",
    "        data.append(image)\n",
    "        labels.append(0)\n",
    "        \n",
    "    d = {}\n",
    "    d['data'] = data\n",
    "    d['labels'] = labels\n",
    "    pickle.dump(d, open('data2.pkl', 'wb'))\n",
    "else:\n",
    "    d = pickle.load(open( 'data2.pkl', 'rb'))\n",
    "    data = d['data']\n",
    "    labels = d['labels']\n",
    "               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.array(data, dtype=\"float\") / 255.0\n",
    "labels = np.array(labels)\n",
    "\n",
    "(x_train, x_test, y_train, y_test) = train_test_split(data,labels, test_size=0.20, random_state=42)\n",
    "y_train = to_categorical(y_train, num_classes=2)\n",
    "y_test = to_categorical(y_test, num_classes=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (2497, 128, 128, 3)\n",
      "2497 train samples\n",
      "625 test samples\n",
      "Train on 2497 samples, validate on 625 samples\n",
      "Epoch 1/10\n",
      "2497/2497 [==============================] - 471s 189ms/step - loss: 0.6477 - acc: 0.6386 - val_loss: 0.6843 - val_acc: 0.5488\n",
      "Epoch 2/10\n",
      "2497/2497 [==============================] - 2623s 1s/step - loss: 0.6076 - acc: 0.6748 - val_loss: 0.6039 - val_acc: 0.6680\n",
      "Epoch 3/10\n",
      "2497/2497 [==============================] - 952s 381ms/step - loss: 0.5708 - acc: 0.7119 - val_loss: 0.5773 - val_acc: 0.6976\n",
      "Epoch 4/10\n",
      "2497/2497 [==============================] - 824s 330ms/step - loss: 0.5504 - acc: 0.7179 - val_loss: 0.6099 - val_acc: 0.6952\n",
      "Epoch 5/10\n",
      "2497/2497 [==============================] - 709s 284ms/step - loss: 0.5425 - acc: 0.7247 - val_loss: 0.6172 - val_acc: 0.6848\n",
      "Epoch 6/10\n",
      "2497/2497 [==============================] - 657s 263ms/step - loss: 0.5305 - acc: 0.7333 - val_loss: 0.5630 - val_acc: 0.7048\n",
      "Epoch 7/10\n",
      "2497/2497 [==============================] - 540s 216ms/step - loss: 0.4870 - acc: 0.7597 - val_loss: 0.5682 - val_acc: 0.7096\n",
      "Epoch 8/10\n",
      "2497/2497 [==============================] - 557s 223ms/step - loss: 0.4660 - acc: 0.7799 - val_loss: 0.5844 - val_acc: 0.7040\n",
      "Epoch 9/10\n",
      "2497/2497 [==============================] - 471s 189ms/step - loss: 0.4249 - acc: 0.7966 - val_loss: 0.6026 - val_acc: 0.6904\n",
      "Epoch 10/10\n",
      "2497/2497 [==============================] - 474s 190ms/step - loss: 0.3758 - acc: 0.8350 - val_loss: 0.7321 - val_acc: 0.6824\n",
      "score =  0.6824000004768371\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.65      0.74      0.70       308\n",
      "          1       0.71      0.64      0.67       317\n",
      "\n",
      "avg / total       0.68      0.69      0.68       625\n",
      "\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "num_classes = 2\n",
    "epochs = 10\n",
    "\n",
    "img_rows, img_cols = 128, 128\n",
    "\n",
    "input_shape = (img_rows, img_cols,3)\n",
    "\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), padding='same', activation='relu', input_shape=input_shape))\n",
    "model.add(Conv2D(32, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), padding='same', activation='relu'))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), padding='same', activation='relu'))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, verbose=1,validation_data=(x_test, y_test))\n",
    "\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('score = ',score[1])\n",
    "y_p = model.predict(x_test)\n",
    "\n",
    "\n",
    "print(classification_report(y_test, y_p.round()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
